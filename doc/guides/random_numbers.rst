.. _random_numbers:

Random numbers
==============

Introduction
------------

Random numbers are used for a variety of purposes in neuronal network
simulations, e.g.

-  to create randomized connections

-  to choose parameter values randomly

-  to inject noise into network simulations, e.g., in the form of
   Poissonian spike trains.

This document discusses how NEST provides random numbers for these
purposes, how you can choose which random number generator (RNG) to
choose, and how to set the seed of RNGs in NEST. We use the term "random
number" here for ease of writing, even though we are always talking
about pseudorandom numbers generated by some algorithm.

NEST is designed to support parallel simulation and this puts some
constraints on the use and generation of random numbers. We discuss
these in the next section, before going into the details of how to
control RNGs in NEST.

On this page, we mainly discuss the use of random numbers in parallel
NEST simulations, but the comments pertain equally to serial simulations
\\(N\_{vp}=1\\).

This guide provides an overview over how to :ref:`seed and select <seeding>` RNGs,
how to correctly use Python RNGs to :ref:`randomize the membrane potential <rand_vm>`
(or other properties) and how to perform :ref:`consistency checks on parallel simulations <testing_rands>`.
It also provides background information on :ref:`parallel simulation and randomness <basic_para>` 
and some information on :ref:`SLI-level generators <sli_generators>` which are 
mostly of historical interest.

.. note::
   
   NEST 3.0 will include a significantly revised and more convenient
   interface to random numbers.

.. _seeding:

Seeding and selecting random generators
---------------------------------------

In a parallel NEST simulation with \\(N\_{vp}\\) virtual processes, 
NEST requires \\(N\_{vp}+1\\) random number generators. If you want
to randomize network parameters from the Python level, you additionally
need \\(N\_{vp}\\) Python random number generators. 

See :ref:`Basics of Parallel Simulation in NEST <basic_para>` for background
information on these requirements and :ref:`Randomizing the membrane potential <rand_vm>`
for an example of using Python random number generators.


Seeding the random generators
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each of the \\(N\_{vp}\\) random generators needs to be seeded with a
different seed to generate a different random number sequences. We
recommend that you choose a *master seed* ``msd`` and seed the
\\(2N\_{vp}+1\\) generators with seeds ``msd``, ``msd+1``, ...,
``msd+2*N_vp``. Master seeds for for independent experiments must differ
by at least \\(2N\_{vp}+1\\) . Otherwise, the same sequence(s) would
enter in several experiments.

When seeding the random number generators in the NEST kernel, you should
always seed the global and per-process RNGs.

Seeding the global RNG
^^^^^^^^^^^^^^^^^^^^^^

The global NEST rng is seeded with a single, positive integer number:

::

    nest.SetKernelStatus({’grng_seed’ : msd})
    
``msd`` is the master seed, choose your own!

Seeding the per-process RNGs
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The per-process RNGs are seeded by a list of \\(N\_{vp}\\) positive
integers:

::

    nest.SetKernelStatus({’rng_seeds’ : range(msd+1, msd+N_vp+1)})


Seeding the Python RNGs
^^^^^^^^^^^^^^^^^^^^^^^

You can create a properly seeded list of \\(N\_{vp}\\) RNGs on the
Python side using

::

    import numpy
    msd = 123456
    N_vp = nest.GetKernelStatus(['total_num_virtual_procs'])[0]
    pyrngs = [numpy.random.RandomState(s) for s in range(msd+N_vp+1, msd+2*N_vp+1)]




Choosing the random generator type
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Python and NumPy have the `MersenneTwister
MT19937ar <http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html>`__
random number generator built in. There is no simple way of choosing a
different generator in NumPy, but as the MT19937ar appears to be a very
robust generator, this should not cause significant problems.

NEST uses by default Knuth's lagged Fibonacci random number generator
(The Art of Computer Programming, vol 2, 3rd ed, 9th printing or later,
ch 3.6). If you want to use other generators, you can exchange them as
described below. If you have built NEST without the GNU Science Library
(GSL), you will only have the Mersenne Twister MT19937ar and Knuth's
lagged Fibonacci generator available. Otherwise, you will also have some
60 generators from the GSL at your disposal (not all of them
particularly good). You can see the full list of RNGs using

::

    nest.sli_run('rngdict info')

Setting a different global RNG
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To set a different global RNG in NEST, you have to pass a NEST random
number generator object to the NEST kernel. This can currently only be
done by writing some SLI code. The following code replaces the current
global RNG with MT19937 seeded with 101:

::

    nest.sli_run('0 << /grng rngdict/MT19937 :: 101 CreateRNG >> SetStatus')

The following happens here:

-  ``rngdict/MT19937 ::`` fetches a "factory" for MT19937 from the
   ``rngdict``

-  ``101 CreateRNG`` uses the factory to create a single MT19937
   generator with seed 101

-  This is generator is then passed to the ``/grng`` status variable of
   the kernel. This is a "write only" variable that is invisible in
   ``GetKernelStatus()``.

Setting different per-processes RNGs
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

One always needs to exchange all \\(N\_{vp}\\) per-process RNGs at once.
This is done by (assuming \\(N\_{vp}=2\\) ):

::

    nest.sli_run('0 << /rngs [102 103] { rngdict/MT19937 :: exch CreateRNG } Map >> SetStatus')

The following happens here:

-  ``[102 103] { rngdict/MT19937 :: exch CreateRNG } Map`` creates an
   array of two RNG objects seeded with 102 and 103, respectively.

-  This array is then passed to the ``/rngs`` status variable of the
   kernel. This variable is invisible as well.


.. _rand_vm:


Randomizing the membrane potential
----------------------------------

If you want to randomize the membrane potential (or any other property
of a neuron), you need to take care that each node is updated by the
process on which it is local using the per-VP RNG for the VP to which
the node belongs. This is achieved by the following code

::

    pyrngs = [numpy.random.RandomState(s) for s in range(msd, msd+N_vp)]
    nodes   = nest.Create('iaf_psc_delta', 10)
    node_info   = nest.GetStatus(nodes)
    local_nodes = [(ni['global_id'], ni['vp']) for ni in node_info if ni['local']]
    for gid,vp in local_nodes:
       nest.SetStatus([gid], {'V_m': pyrngs[vp].uniform(-70.0, -50.0)})

The first line generates \\([N\_{vp}\\) properly seeded NumPy RNGs as
discussed above. The next line creates 10 nodes, while the third line
extracts status information about each node. For local nodes, this will
be full information, for non-local nodes we only get the following
fields: ``local``, ``model`` and ``type``. On the fourth line, we create
a list of tuples, containing global ID and virtual process number for
all local neurons. The for loop then sets the membrane potential of each
local neuron drawn from a uniform distribution on \\([-70, -50]\\) using
the Python-side RNG for the VP to which the neuron belongs.


.. _testing_rands:

Testing simulations containing randomness
-----------------------------------------

To ensure that you are consistently using the correct RNG for each node
or connection, you should run your simulation several times the same
\\(N\_{vp}\\), but using different numbers of MPI processes. To this
end, add towards the beginning of your script

::

    nest.SetKernelStatus({"total_num_virtual_procs": 4})

and ensure that spikes are logged to file in the current working
directory. Then run the simulation with different numbers of MPI
processes in separate directories

::

     mkdir 41 42 44
     cd 41
     mpirun -np 1 python test.py
     cd ../42
     mpirun -np 2 python test.py
     cd ../44
     mpirun -np 4 python test.py
     cd ..

These directories should now have identical content, something you can
check with ``diff``:

::

    diff 41 42
    diff 41 44

These commands should not generate any output. Obviously, this test
checks only a necessary, but by no means sufficient condition for a
correct simulation. (Oh yes, do make sure that these directories contain
data! Nothing easier than to pass a diff-test on empty dirs.)



.. _basic_para:

Basics of parallel simulation in NEST
-------------------------------------

For details of parallelization in NEST, please see :doc:`Parallel
Computing <parallel_computing>` and `Plesser et al
(2007) <http://dx.doi.org/10.1007/978-3-540-74466-5_71>`__. Here, we
just summarize a few basics.

-  NEST can parallelize simulations through *multi-threading*,
   *distribution*, or a combination of the two.

-  A distributed simulation is spread across several processes under the
   control of MPI (Message Passing Interface). Each network node is
   *local* to exactly one process and complete information about the
   node is only available to that process. Information about each
   connection is stored by the process in which the connection target is
   local and is only available and changeable on that process.

-  Multi-threaded simulations run in a single process in a single
   computer. As a consequence, all nodes in a multi-threaded simulation
   are local.

-  Distribution and multi-threading can be combined by running identical
   numbers of threads in each process.

-  A serial simulation has a single process with a single seed.

-  From the NEST user perspective, distributed processes and threads are
   visible as **virtual processes**. A simulation distributed across
   \\(M\\) MPI processes with \\(T\\) threads each, has \\(N\_{vp} = M
   \\times T\\) virtual processes. It is a basic design principle of NEST
   that simulations shall generate *identical* results when run with a
   fixed \\(N\_{VP}\\), no matter how the virutal processes are broken
   down into MPI processes and threads.

-  Useful information can be obtained like this

::

   import nest 
   nest.NumProcesses() # number of MPI processes 
   nest.Rank()         # rank of MPI process executing command
   nest.GetKernelStatus(['local_num_threads']) # number of threads in present process (same for all processes)
   nest.GetKernelStatus(['total_num_virtual_procs']) # N_vp = M x T

-  When querying neurons, only very limited information is available for
   neurons on other MPI processes. Thus, before checking for specific
   information, you need to check if a node is local:

::

   n = nest.Create('iaf_psc_alpha') 
   if nest.GetStatus(n, 'local')[0]:
       print(nest.GetStatus(n, 'vp'))     # virtual process "owning" node 
       print(nest.GetStatus(n, 'thread')) # thread in calling process "owning" node

Random numbers in parallel simulations
--------------------------------------

Ideally, all random numbers in a simulation should come from a single
RNG. This would require shipping truckloads of random numbers from a
central RNG process to all simulation processes and is thus
impractical, if not outright extremely costly. Therefore, parallel
simulation requires an RNG on each parallel process. Advances in RNG
technology give us a range of RNGs that can be used in parallel,
with a quite high level of certainty that the resulting parallel streams
of random numbers are non-overlapping and uncorrelated. While the former
can be guaranteed, we are not aware of any generator for which the
latter can be proven.

How many generators in a simulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In a typical PyNEST simulation running on \\(N\_{vp}\\) virtual
processes, we will encounter \\(2 N\_{vp} + 1\\) random number
generators:

| The global NEST RNG
| This generator is mainly used when creating connections using
  ``fixed_outdegree`` connection rule.

| One RNG per VP in NEST
| These generators are used when creating connections using
  most other probabilistic connection rules and to provide random numbers to nodes
  generating random output, e.g., the ``poisson_generator``.

| One RNG per VP in Python
| These generators are used to randomize node properties (e.g., the
  initial membrane potential) and connection properties (e.g., weights).

The generators on the Python level are not strictly necessary, as one
could in principle access the per-VP RNGs built into NEST. This would
require very tedious SLI-coding, though. We therefore recommend at
present that you use additional RNGs on the Python side.

Why a global RNG in NEST?
^^^^^^^^^^^^^^^^^^^^^^^^^

In some situations, randomized decisions on different virtual processes
are not independent of each other. The most important cases are
randomized divergent connections. The problem here is as follows. For
the sake of efficiency, NEST stores all connection information in the
virtual process (VP) to which the target of a connection resides (target
process). Thus, all connections are generated by this target process.
Now consider the task of generating 100 randomized divergent connections
originating from a given source neuron while using 4 VPs. Then there
should be 25 targets on each VP *on average*, but actual numbers will
fluctuate. If independent processes on all VPs tried to choose target
neurons, we could never be sure that exactly 100 targets would be chosen
in total.

NEST thus creates divergent connections using a global RNG. This random
number generator provides the exact same sequence of random numbers on
each virtual process. Using this global RNG, each VP chooses 100 targets
from the entire network, but actually creates connections only for those
targets that reside on the VP. In practice, the global RNG is
implemented using one "clone" on each VP; NEST checks occasionally that
all these clones are synchronized, i.e., indeed generate identical
sequences.


.. _sli_generators:

Generators available at the SLI level
-------------------------------------

This section is of historical interest only. Generators described here
will no longer be available in NEST 3.0

Random numbers vs random deviates
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

NEST distinguishes between random number generators, provided by
``rngdict`` and random deviate generators provided by ``rdevdict``.
Random *number* generators only provide double-valued numbers uniformly
distributed on [0, 1] and uniformly distributed integers in {0, 1, ...,
N}. Random *deviate* generators, on the other hand, provide random
numbers drawn from a range of distributions, such as the normal or
binomial distributions. In most cases, you will be using random deviate
generators. 


Random Deviates 
~~~~~~~~~~~~~~~

NEST provides the following random deviate generators for use at the SLI
level:

- binomial
- exponential
- gamma
- lognormal
- normal
- poisson
- uniform
- uniform_int


-  Clipped variants for most generators

   -  For most random deviate generators, ``_clipped`` variants exist
      now.

   -  For all clipped variants, one can set a lower limit (``low``,
      default: -infinity) and an upper limit (``high``: +infinty).

   -  Clipped variants will then return numbers strictly in
      ``(low, high)`` for continuous distributions (e.g. normal,
      exponential) or ``{low, low+1, …, high}`` for discrete
      distributions (e.g. poisson, binomial). This is achieved by
      redrawing numbers until an acceptable number is drawn.

   -  Note that the resulting distribution differs from the original one
      and that drawing may become very slow if ``(low, high)`` contains
      only a very small probability mass. Clipped generator variants
      should therefore mostly be used to clip tails with very small
      probability mass when randomizing time constants or delays.

-  Clipped-to-boundary variants for most generators

   -  To facilitate reproduction of certain publications, NEST also
      provides ``_clipped_to_boundary`` variants of most generators.

   -  Clipped-to-boundary variants return the value ``low`` if a number
      smaller than ``low`` is drawn, and ``high`` if a number larger
      than ``high`` is drawn.

   -  We believe that these variants should *not* be used for new
      studies.
